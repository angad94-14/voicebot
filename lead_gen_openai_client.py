import streamlit as st
import openai
import sounddevice as sd
import soundfile as sf
import numpy as np
import tempfile
import os
import json
from datetime import datetime
import base64
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Page configuration
st.set_page_config(
    page_title="Voice Loan Assistant / ‡§µ‡•â‡§á‡§∏ ‡§≤‡•ã‡§® ‡§Ö‡§∏‡§ø‡§∏‡•ç‡§ü‡•á‡§Ç‡§ü",
    page_icon="üéôÔ∏è",
    layout="centered"
)


# Initialize OpenAI client
@st.cache_resource
def get_openai_client():
    return openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


client = get_openai_client()

# Initialize session state
if "conversation" not in st.session_state:
    st.session_state.conversation = []
if "is_recording" not in st.session_state:
    st.session_state.is_recording = False
if "audio_data" not in st.session_state:
    st.session_state.audio_data = None
if "leads" not in st.session_state:
    st.session_state.leads = []
if "current_lead" not in st.session_state:
    st.session_state.current_lead = {}
if "language_preference" not in st.session_state:
    st.session_state.language_preference = "English"

# Hindi-English financial services knowledge
HINDI_SYSTEM_PROMPT = """You are a helpful bilingual voice assistant for a financial services company in India. You can communicate in both Hindi and English based on user preference.

Our services include:
‡§π‡§Æ‡§æ‡§∞‡•Ä ‡§∏‡•á‡§µ‡§æ‡§è‡§Ç / Our Services:
- ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø‡§ó‡§§ ‡§≤‡•ã‡§® (Personal Loans): ‚Çπ50,000 ‡§§‡§ï ‡§ï‡§æ ‡§Ö‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§ø‡§§ ‡§≤‡•ã‡§® / Unsecured loans up to ‚Çπ50,000
- ‡§µ‡•ç‡§Ø‡§æ‡§™‡§æ‡§∞‡§ø‡§ï ‡§≤‡•ã‡§® (Business Loans): ‡§µ‡•ç‡§Ø‡§æ‡§™‡§æ‡§∞ ‡§µ‡§ø‡§∏‡•ç‡§§‡§æ‡§∞ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§´‡§Ç‡§°‡§ø‡§Ç‡§ó / Funding for business expansion  
- ‡§ã‡§£ ‡§∏‡§Æ‡•á‡§ï‡§® (Debt Consolidation): ‡§ï‡§à ‡§ã‡§£‡•ã‡§Ç ‡§ï‡•ã ‡§è‡§ï ‡§≠‡•Å‡§ó‡§§‡§æ‡§® ‡§Æ‡•á‡§Ç ‡§Æ‡§ø‡§≤‡§æ‡§®‡§æ / Combine multiple debts into one payment

Key eligibility / ‡§™‡§æ‡§§‡•ç‡§∞‡§§‡§æ ‡§Æ‡§æ‡§™‡§¶‡§Ç‡§°:
- 18+ ‡§µ‡§∞‡•ç‡§∑ ‡§Ü‡§Ø‡•Å / 18+ years old
- ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§®‡§ø‡§µ‡§æ‡§∏‡•Ä / Indian resident  
- ‡§∏‡•ç‡§•‡§ø‡§∞ ‡§Ü‡§Ø / Steady income
- ‡§ï‡•ç‡§∞‡•á‡§°‡§ø‡§ü ‡§∏‡•ç‡§ï‡•ã‡§∞ 600+ / Credit score 600+

IMPORTANT INSTRUCTIONS:
- Respond in the same language the user speaks (Hindi or English)
- If user speaks Hindi, respond in Hindi with some English financial terms
- If user speaks English, respond in English
- Keep responses conversational and under 2 sentences for voice delivery
- For Hindi speakers, use familiar terms like "‡§≤‡•ã‡§®", "‡§¨‡•ç‡§Ø‡§æ‡§ú ‡§¶‡§∞", "‡§ï‡§ø‡§∏‡•ç‡§§"
- When someone shows interest, offer to collect their information
- Be respectful and use appropriate Hindi honorifics like "‡§ú‡•Ä", "‡§Ü‡§™"

Available demo account IDs for testing: demo123, biz456, consol789"""

ENGLISH_SYSTEM_PROMPT = """You are a helpful voice assistant for a financial services company specializing in loans.

Our services include:
- Personal Loans: Unsecured loans up to $50,000 for various needs
- Business Loans: Funding solutions for business growth and expansion  
- Debt Consolidation: Combine multiple debts into one manageable payment

Key eligibility requirements:
- 18+ years old, US/India resident
- Steady income, Credit score 600+
- Debt-to-income ratio below 40%

Keep responses conversational and under 2 sentences for voice delivery.
When someone shows interest in applying, offer to collect their information.
Available demo account IDs: demo123, biz456, consol789"""

# Function definitions for OpenAI
lead_capture_functions = [
    {
        "name": "capture_lead_info",
        "description": "Capture customer lead information when they express interest in applying for a loan",
        "parameters": {
            "type": "object",
            "properties": {
                "name": {"type": "string", "description": "Customer's full name"},
                "email": {"type": "string", "description": "Customer's email address"},
                "phone": {"type": "string", "description": "Customer's phone number"},
                "loan_type": {"type": "string", "description": "Type of loan they're interested in"},
                "loan_amount": {"type": "number", "description": "Desired loan amount"},
                "language": {"type": "string", "description": "Preferred language (Hindi/English)"}
            },
            "required": ["name", "phone", "loan_type"]
        }
    },
    {
        "name": "lookup_account_info",
        "description": "Look up account information using account ID",
        "parameters": {
            "type": "object",
            "properties": {
                "account_id": {"type": "string", "description": "Account ID or access code"}
            },
            "required": ["account_id"]
        }
    }
]


def detect_language(text):
    """Simple language detection"""
    hindi_chars = any(ord(char) >= 0x0900 and ord(char) <= 0x097F for char in text)
    return "Hindi" if hindi_chars else "English"


def handle_function_call(function_name, arguments, detected_language):
    """Handle function calls with bilingual responses"""
    if function_name == "capture_lead_info":
        lead_data = {
            **arguments,
            "timestamp": datetime.now().isoformat(),
            "status": "new",
            "detected_language": detected_language
        }
        st.session_state.leads.append(lead_data)
        st.session_state.current_lead = lead_data

        # Save to file
        save_leads_to_file()

        name = arguments.get('name', '')
        loan_type = arguments.get('loan_type', 'loan')

        if detected_language == "Hindi":
            return f"‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶ {name} ‡§ú‡•Ä! ‡§Æ‡•à‡§Ç‡§®‡•á ‡§Ü‡§™‡§ï‡•Ä {loan_type} ‡§ï‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§≤‡•á ‡§≤‡•Ä ‡§π‡•à‡•§ ‡§π‡§Æ‡§æ‡§∞‡§æ ‡§≤‡•ã‡§® ‡§è‡§°‡§µ‡§æ‡§á‡§ú‡§∞ 24 ‡§ò‡§Ç‡§ü‡•á ‡§Æ‡•á‡§Ç ‡§Ü‡§™‡§∏‡•á ‡§∏‡§Ç‡§™‡§∞‡•ç‡§ï ‡§ï‡§∞‡•á‡§ó‡§æ‡•§"
        else:
            return f"Thank you {name}! I've captured your information for a {loan_type}. A loan advisor will contact you within 24 hours."

    elif function_name == "lookup_account_info":
        account_id = arguments.get("account_id", "").lower()
        # Mock account data
        accounts = {
            "demo123": {
                "balance": 18750,
                "payment": 485,
                "due_date": "2025-06-15"
            }
        }

        account = accounts.get(account_id)
        if account:
            if detected_language == "Hindi":
                return f"‡§Ü‡§™‡§ï‡§æ ‡§ñ‡§æ‡§§‡§æ ‡§µ‡§ø‡§µ‡§∞‡§£: ‡§µ‡§∞‡•ç‡§§‡§Æ‡§æ‡§® ‡§∂‡•á‡§∑ ‚Çπ{account['balance']:,}, ‡§Ö‡§ó‡§≤‡•Ä ‡§ï‡§ø‡§∏‡•ç‡§§ ‚Çπ{account['payment']} ‡§¶‡§ø‡§®‡§æ‡§Ç‡§ï {account['due_date']} ‡§ï‡•ã ‡§¶‡•á‡§®‡•Ä ‡§π‡•à‡•§"
            else:
                return f"Your account info: Current balance ‚Çπ{account['balance']:,}, next payment ‚Çπ{account['payment']} due on {account['due_date']}."
        else:
            if detected_language == "Hindi":
                return "‡§ñ‡•Å‡§∂‡•Ä! ‡§á‡§∏ ‡§Ü‡§à‡§°‡•Ä ‡§∏‡•á ‡§ï‡•ã‡§à ‡§ñ‡§æ‡§§‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡§æ‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§Ö‡§™‡§®‡§æ ‡§ñ‡§æ‡§§‡§æ ‡§Ü‡§à‡§°‡•Ä ‡§ú‡§æ‡§Ç‡§ö‡•á‡§Ç‡•§"
            else:
                return "Sorry! I couldn't find an account with that ID. Please check your account ID."

    return "I'm sorry, I couldn't process that request."


def save_leads_to_file():
    """Save leads to JSON file"""
    try:
        with open('captured_leads.json', 'w', encoding='utf-8') as f:
            json.dump(st.session_state.leads, f, indent=2, ensure_ascii=False)
    except Exception as e:
        pass  # Silent fail for POC


def record_audio(duration=5, sample_rate=16000):
    """Record audio from microphone"""
    try:
        audio_data = sd.rec(int(duration * sample_rate),
                            samplerate=sample_rate,
                            channels=1,
                            dtype=np.float32)
        sd.wait()
        return audio_data.flatten()
    except Exception as e:
        st.error(f"Recording failed: {str(e)}")
        return None


def save_audio_to_temp(audio_data, sample_rate=16000):
    """Save audio data to temporary file"""
    try:
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
        sf.write(temp_file.name, audio_data, sample_rate)
        return temp_file.name
    except Exception as e:
        st.error(f"Failed to save audio: {str(e)}")
        return None


def transcribe_audio(audio_file_path, language_hint=None):
    """Convert speech to text using OpenAI Whisper with language hint"""
    try:
        with open(audio_file_path, "rb") as audio_file:
            # Add language parameter for better Hindi recognition
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language="hi" if language_hint == "Hindi" else None  # Hindi language code
            )
        return transcript.text
    except Exception as e:
        st.error(f"Transcription failed: {str(e)}")
        return None


def get_ai_response(user_message, conversation_history, detected_language):
    """Get response from OpenAI GPT-4 with language awareness"""
    try:
        # Choose system prompt based on detected language
        system_prompt = HINDI_SYSTEM_PROMPT if detected_language == "Hindi" else ENGLISH_SYSTEM_PROMPT

        messages = [{"role": "system", "content": system_prompt}]

        # Add conversation history
        for msg in conversation_history[-6:]:  # Keep last 6 messages for context
            messages.append({"role": "user", "content": msg["user"]})
            messages.append({"role": "assistant", "content": msg["assistant"]})

        # Add current message
        messages.append({"role": "user", "content": user_message})

        response = client.chat.completions.create(
            model="gpt-4",
            messages=messages,
            functions=lead_capture_functions,
            function_call="auto",
            max_tokens=200,
            temperature=0.7
        )

        message = response.choices[0].message

        # Handle function calls
        if message.function_call:
            function_name = message.function_call.name
            arguments = json.loads(message.function_call.arguments)
            function_response = handle_function_call(function_name, arguments, detected_language)
            return function_response
        else:
            return message.content

    except Exception as e:
        if detected_language == "Hindi":
            return "‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§ï‡§∞‡•á‡§Ç, ‡§Æ‡•Å‡§ù‡•á ‡§Ü‡§™‡§ï‡§æ ‡§Ö‡§®‡•Å‡§∞‡•ã‡§ß ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏ ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§ï‡•Å‡§õ ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à‡•§"
        else:
            return "I'm sorry, I'm having trouble processing your request right now."


def text_to_speech(text, language_hint=None):
    """Convert text to speech - note: OpenAI TTS may not sound natural for Hindi"""
    try:
        response = client.audio.speech.create(
            model="tts-1",
            voice="nova",  # Best voice for multilingual
            input=text
        )

        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
        response.stream_to_file(temp_file.name)
        return temp_file.name
    except Exception as e:
        st.error(f"Text-to-speech failed: {str(e)}")
        return None


def play_audio_in_browser(audio_file_path):
    """Create audio player for browser"""
    try:
        with open(audio_file_path, "rb") as audio_file:
            audio_bytes = audio_file.read()

        audio_base64 = base64.b64encode(audio_bytes).decode()
        audio_html = f"""
        <audio autoplay>
            <source src="data:audio/mp3;base64,{audio_base64}" type="audio/mp3">
        </audio>
        """
        st.markdown(audio_html, unsafe_allow_html=True)
    except Exception as e:
        st.error(f"Audio playback failed: {str(e)}")


# Main UI
st.title("üéôÔ∏è Voice Loan Assistant / ‡§µ‡•â‡§á‡§∏ ‡§≤‡•ã‡§® ‡§Ö‡§∏‡§ø‡§∏‡•ç‡§ü‡•á‡§Ç‡§ü")
st.markdown("**Ask me about loans in Hindi or English! / ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Ø‡§æ ‡§Ö‡§Ç‡§ó‡•ç‡§∞‡•á‡§ú‡•Ä ‡§Æ‡•á‡§Ç ‡§≤‡•ã‡§® ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§™‡•Ç‡§õ‡•á‡§Ç!**")

# Language preference selector
col1, col2 = st.columns([2, 1])
with col1:
    st.session_state.language_preference = st.selectbox(
        "Preferred Language / ‡§≠‡§æ‡§∑‡§æ ‡§ö‡•Å‡§®‡•á‡§Ç:",
        ["Auto-detect", "English", "Hindi / ‡§π‡§ø‡§Ç‡§¶‡•Ä"],
        index=0
    )

with col2:
    if st.session_state.language_preference == "Hindi / ‡§π‡§ø‡§Ç‡§¶‡•Ä":
        st.info("‚ö†Ô∏è TTS may sound English-accented")

# Voice interaction section
col1, col2 = st.columns([1, 1])

with col1:
    recording_duration = st.selectbox("Recording Duration / ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§°‡§ø‡§Ç‡§ó ‡§∏‡§Æ‡§Ø", [5, 8, 10], index=0)
    if st.button("üé§ Start Recording / ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§°‡§ø‡§Ç‡§ó ‡§∂‡•Å‡§∞‡•Ç ‡§ï‡§∞‡•á‡§Ç", type="primary", disabled=st.session_state.is_recording):
        st.session_state.is_recording = True
        with st.spinner(
                f"Recording for {recording_duration} seconds... / {recording_duration} ‡§∏‡•á‡§ï‡§Ç‡§° ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§° ‡§π‡•ã ‡§∞‡§π‡§æ ‡§π‡•à..."):
            audio_data = record_audio(duration=recording_duration)
            if audio_data is not None:
                st.session_state.audio_data = audio_data
        st.session_state.is_recording = False

with col2:
    if st.button("‚èπÔ∏è Process Voice / ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏ ‡§ï‡§∞‡•á‡§Ç", disabled=st.session_state.audio_data is None):
        if st.session_state.audio_data is not None:
            with st.spinner("Processing your voice... / ‡§Ü‡§™‡§ï‡•Ä ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏ ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à..."):
                temp_audio_path = save_audio_to_temp(st.session_state.audio_data)

                if temp_audio_path:
                    # Determine language hint for Whisper
                    language_hint = None
                    if st.session_state.language_preference == "Hindi / ‡§π‡§ø‡§Ç‡§¶‡•Ä":
                        language_hint = "Hindi"

                    user_text = transcribe_audio(temp_audio_path, language_hint)

                    if user_text:
                        # Detect actual language used
                        detected_language = detect_language(user_text)
                        if st.session_state.language_preference == "Auto-detect":
                            detected_language = detect_language(user_text)
                        elif st.session_state.language_preference == "Hindi / ‡§π‡§ø‡§Ç‡§¶‡•Ä":
                            detected_language = "Hindi"
                        else:
                            detected_language = "English"

                        ai_response = get_ai_response(user_text, st.session_state.conversation, detected_language)
                        tts_audio_path = text_to_speech(ai_response, detected_language)

                        st.session_state.conversation.append({
                            "user": user_text,
                            "assistant": ai_response,
                            "timestamp": datetime.now().strftime("%H:%M:%S"),
                            "language": detected_language
                        })

                        if tts_audio_path:
                            play_audio_in_browser(tts_audio_path)
                            os.unlink(tts_audio_path)

                    os.unlink(temp_audio_path)

            st.session_state.audio_data = None

# Lead capture status
if st.session_state.current_lead:
    name = st.session_state.current_lead.get('name', 'Unknown')
    loan_type = st.session_state.current_lead.get('loan_type', 'Loan')
    lang = st.session_state.current_lead.get('detected_language', 'English')

    if lang == "Hindi":
        st.success(f"‚úÖ ‡§≤‡•Ä‡§° ‡§ï‡•à‡§™‡•ç‡§ö‡§∞ ‡§π‡•Å‡§Ü: {name} - {loan_type} ‡§Ü‡§µ‡•á‡§¶‡§®")
    else:
        st.success(f"‚úÖ Lead captured: {name} - {loan_type} application")

# Conversation History
if st.session_state.conversation:
    st.markdown("---")
    st.subheader("üí¨ Conversation / ‡§¨‡§æ‡§§‡§ö‡•Ä‡§§")

    for msg in reversed(st.session_state.conversation):
        with st.container():
            col1, col2 = st.columns([1, 4])
            with col1:
                lang_flag = "üáÆüá≥" if msg.get('language') == 'Hindi' else "üá∫üá∏"
                st.markdown(f"**{msg['timestamp']}** {lang_flag}")
            with col2:
                st.markdown(f"**You:** {msg['user']}")
                st.markdown(f"**Assistant:** {msg['assistant']}")
            st.markdown("")

# Control buttons
col1, col2 = st.columns([1, 1])
with col1:
    if st.session_state.conversation and st.button("üóëÔ∏è Clear / ‡§∏‡§æ‡§´‡§º ‡§ï‡§∞‡•á‡§Ç"):
        st.session_state.conversation = []
        st.session_state.current_lead = {}
        st.rerun()

# Instructions
with st.expander("‚ÑπÔ∏è How to Use / ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§®‡•á ‡§ï‡§æ ‡§§‡§∞‡•Ä‡§ï‡§æ"):
    st.markdown("""
    **English Instructions:**
    1. Select your preferred language or use auto-detect
    2. Click "Start Recording" and speak clearly for 5-10 seconds
    3. Click "Process Voice" to get AI response
    4. The assistant will respond in the same language you spoke

    **‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂:**
    1. ‡§Ö‡§™‡§®‡•Ä ‡§™‡§∏‡§Ç‡§¶‡•Ä‡§¶‡§æ ‡§≠‡§æ‡§∑‡§æ ‡§ö‡•Å‡§®‡•á‡§Ç ‡§Ø‡§æ ‡§ë‡§ü‡•ã-‡§°‡§ø‡§ü‡•á‡§ï‡•ç‡§ü ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç
    2. "‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§°‡§ø‡§Ç‡§ó ‡§∂‡•Å‡§∞‡•Ç ‡§ï‡§∞‡•á‡§Ç" ‡§™‡§∞ ‡§ï‡•ç‡§≤‡§ø‡§ï ‡§ï‡§∞‡•á‡§Ç ‡§î‡§∞ 5-10 ‡§∏‡•á‡§ï‡§Ç‡§° ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§¨‡•ã‡§≤‡•á‡§Ç
    3. AI ‡§â‡§§‡•ç‡§§‡§∞ ‡§™‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è "‡§Ü‡§µ‡§æ‡§ú‡§º ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏ ‡§ï‡§∞‡•á‡§Ç" ‡§™‡§∞ ‡§ï‡•ç‡§≤‡§ø‡§ï ‡§ï‡§∞‡•á‡§Ç
    4. ‡§Ö‡§∏‡§ø‡§∏‡•ç‡§ü‡•á‡§Ç‡§ü ‡§â‡§∏‡•Ä ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•á‡§Ç ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á‡§ó‡§æ ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç ‡§Ü‡§™‡§®‡•á ‡§¨‡§æ‡§§ ‡§ï‡•Ä ‡§π‡•à

    **Sample Questions / ‡§®‡§Æ‡•Ç‡§®‡§æ ‡§™‡•ç‡§∞‡§∂‡•ç‡§®:**
    - "What loan options do you have?" / "‡§Ü‡§™‡§ï‡•á ‡§™‡§æ‡§∏ ‡§ï‡•å‡§® ‡§∏‡•á ‡§≤‡•ã‡§® ‡§ï‡•á ‡§µ‡§ø‡§ï‡§≤‡•ç‡§™ ‡§π‡•à‡§Ç?"
    - "I need a personal loan" / "‡§Æ‡•Å‡§ù‡•á ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø‡§ó‡§§ ‡§≤‡•ã‡§® ‡§ö‡§æ‡§π‡§ø‡§è"
    - "Account ID demo123 ki jankari dijiye"

    **Note:** Hindi TTS may sound English-accented due to OpenAI limitations.
    """)

# Environment check
if not os.getenv("OPENAI_API_KEY"):
    st.error("‚ö†Ô∏è OpenAI API key not found. Please set OPENAI_API_KEY in your .env file.")